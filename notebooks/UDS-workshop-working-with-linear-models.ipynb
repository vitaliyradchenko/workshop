{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--<h1 style=\"font-size:40px; font-family:Verdana\" align=\"center\"> UDS-Club Workshop </h1> -->\n",
    "<h2 style=\"font-size:34px; font-family:Verdana\" align=\"center\">Linear Models </h2>\n",
    "<!-- <img src='http://www.cmu.edu/africa/files/images/AppliedMachineLearningLogo.png'/> -->\n",
    "<img src='https://files.slack.com/files-pri/T41777KHA-F4TTMNKNK/ua-parrots.jpg'/>\n",
    "<h4 style=\"font-size:18px; font-family:Verdana\" align=\"right\"> by Sergii Romanenk <br> <pre>    2017-04-23</pre> </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080\">\n",
    "<h2 style=\"font-size:25px; font-family:Verdana\" align=\"left\"> Table of Contents </h2>\n",
    "<ol>\n",
    "    <li style=\"font-size:20px; font-family:Verdana\">[Naive Bayes](#1)</li>\n",
    "    <li style=\"font-size:20px; font-family:Verdana\">[Passive Aggressive Classifier](#2)\n",
    "        <ul> \n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[Introduction to online learning](#2_1)</li>\n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[Three Decision Problems ](#2_2)</li>\n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[PassiveAgressive](#2_3)</li>\n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[Three variants of the Passive-Aggressive algorithm](#2_4)</li>             </ul>\n",
    "    </li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080\">\n",
    "## 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a fundamental issue in machine learning and data mining. In classification, the goal of a learning algorithm is to construct a classifier given a set of training examples with class labels. Typically, an example $E$ is represented by a tuple of attribute values ($x_1, x_2, … , x_n$), where $x_i$ is the value of attribute $X_i$. \n",
    "\n",
    "Let $C$ represent the classification variable, and let $c$ be the value of $C$. In this paper, we assume that there are only two classes: + (the positive class) or − (the negative class).\n",
    "\n",
    "A classifier is a function that assigns a class label to an example. From the probability perspective, according to Rule, the probability of an example $E = (x_1, x_2, … , x_n)$ being class $c$ is\n",
    "\n",
    "$$p(c|E) = {\\frac{p(E|c)p(c)}{p(E)}}$$\n",
    "\n",
    "$E$ is classified as the class $C = +$ if and only if\n",
    "$$f_b(E) = {\\frac{p(C = +|E)}{p(C = -|E)}}\\geq1$$\n",
    "\n",
    "\n",
    "where $f_b(E)$ is called a Bayesian classifier. Assume that all attributes are independent given the value of the class variable; that is,\n",
    "$$p(E|c) = p(x_1, x_2, … , x_n|c) = \\prod\\limits_{i = 1}^n p(x_i|c)$$\n",
    "the resulting classifier is then:\n",
    "$$f_{nb}(E) = {\\frac{p(C = +)}{p(C = -)}} \\prod\\limits_{i = 1}^n {\\frac{p(x_i|c = +)}{p(x_i|c = -)}} $$\n",
    "The function $f_{nb}(E)$ is called a naive Bayesian classifier, or simply naive Bayes (NB). Figure 1 shows an example of naive Bayes. In naive Bayes, each attribute node has no parent except the class node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.slack.com/files-pri/T41777KHA-F503T9C4W/nb5.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is the simplest form of Bayesian network, in which all attributes are independent given the value of the class variable. This is called conditional independence. It is obvious that the conditional independence assumption is rarely true in most real-world applications. A straightforward approach to overcome the limitation of naive Bayes is to extend its structure to represent explicitly the dependencies among attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080 border: dashed 1px\">\n",
    "## 2. Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "### 2.1 Introduction to online learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Online Learning is generally described as doing machine learning in a streaming data setting, i.e. training a model in consecutive rounds. After each observation, the algorithm predicts an outcome.\n",
    "<ul>\n",
    "    <li> Once the algorithm has made a prediction, it receives feedback indicating the correct outcome </li>\n",
    "    <li> Then, the online algorithm may modify its prediction mechanism, presumably improving the chances of making an accurate prediction on subsequent rounds </li>    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.doyensahoo.com/uploads/5/3/7/3/53734297/6829966.jpg?758' width ='60%' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li> For PA we use instantaneous loss which reflects the degree to which its prediction was wrong. This loss is defined by the following hinge-loss function: </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://files.slack.com/files-pri/T41777KHA-F4ZBF9H27/hinge-loss.jpg' width ='60%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Online algorithms are useful in an least two scenarios:\n",
    "<ul>\n",
    "<li> When your data is too large to fit in the memory </li>\n",
    "<li type=\"circle\" style=\"margin-left: 40px;\"> So you need to train your model one example at a time </li>\n",
    "<li> When new data is constantly being generated and/or is dependent upon time </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "### 2.2  Three Decision Problems \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://files.slack.com/files-pri/T41777KHA-F4YN5P6RE/3decision-problems.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will look only on classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "### 2.3 PassiveAgressive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://files.slack.com/files-pri/T41777KHA-F4YN5S15W/pac.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://files.slack.com/files-pri/T41777KHA-F4ZBFAQRH/pa.jpg' width ='70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting algorithm is <i>passive</i> whenever the <i>hinge-loss</i> is zero, that is, $w_{t+1} = w_t$ whenever $ℓ_t = 0$. \n",
    "In contrast, on those rounds where the loss is positive, the algorithm <i>aggressively</i> forces wt+1 to satisfy the constraint $ℓ(w_{t+1}; (x_t , y_t)) = 0 $ regardless of the step-size required. \n",
    "We therefore name the algorithm <i>Passive-Aggressive</i> or PA for short.\n",
    "\n",
    "The solution to the optimization problem in Eq. (2) has a simple closed form solution,\n",
    "$$w_{t+1} = w_t + \\tau_ty_tx_t \\text{ where } \\tau_t = {\\frac{l_t}{\\|x_t\\|^2}} \\text{ (3)}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "\n",
    "### 2.4 Three variants of the Passive-Aggressive algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://files.slack.com/files-pri/T41777KHA-F4ZECMJNQ/pas.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C -- aggressiveness parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data import\n",
    "train = pd.read_csv('./data/movie_reviews.csv', sep = ',')\n",
    "train_data = train.text\n",
    "train_labels = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "BASE_DIR = ''\n",
    "TEXT_DATA_DIR = BASE_DIR + './data/test'\n",
    "TEXT_DATA_FILE_1 = \"rt-polarity_neg.txt\"\n",
    "TEXT_DATA_FILE_2 = \"rt-polarity_pos.txt\"\n",
    "HEADER = True\n",
    "\n",
    "def load_data():\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in [TEXT_DATA_FILE_1, TEXT_DATA_FILE_2]:\n",
    "        with open(os.path.join(TEXT_DATA_DIR, i), \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "            if HEADER:\n",
    "                _ = next(f)\n",
    "            if i[-7:-4] == \"pos\":\n",
    "                temp_y = 1\n",
    "            else: temp_y = 0\n",
    "            for line in f:\n",
    "                x.append(line.rstrip(\"\\n\"))\n",
    "                y.append(temp_y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "test_data, test_labels = load_data()\n",
    "test_labels = np.asarray(test_labels, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the last 22 words from each review in the train set\n",
    "train_data = train_data.str.split().apply(lambda x:  ' '.join(x for x in x[-22:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "STOPWORDS = ['by','does', 'was', 'were', 'the', 'of', 'end', 'and', 'is']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvect = CountVectorizer()\n",
    "counts = cvect.fit_transform(train_data)\n",
    "\n",
    "classifier = PassiveAggressiveClassifier(C=0.001, fit_intercept = False, shuffle = False, n_iter = 91, n_jobs = -1)\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(binary=True,ngram_range=(1,4),stop_words=STOPWORDS)), ('classifier', classifier)])\n",
    "model = pipeline.fit(X=train_data, y=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.800187617261\n"
     ]
    }
   ],
   "source": [
    "# Compare Validation Accuracy on RT, IMDB and mixed test sets\n",
    "pred_test = model.predict(test_data)\n",
    "\n",
    "print (\"Accuracy :\", metrics.accuracy_score(test_labels, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
